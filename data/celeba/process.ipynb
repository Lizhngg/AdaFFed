{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_identities = open(os.path.join('raw_data', 'identity_CelebA.txt'), 'r')\n",
    "identities = f_identities.read().split('\\n')\n",
    "\n",
    "f_attributes = open(os.path.join('raw_data', 'list_attr_celeba.txt'), 'r')\n",
    "attributes = f_attributes.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = 'Smiling'\n",
    "sen_attr = 'Male'\n",
    "\n",
    "target_idx = attributes[1].split().index(tar)\n",
    "sen_idx = attributes[1].split().index(sen_attr)\n",
    "image, target, sensitive = {},[],[]\n",
    "#https://zhuanlan.zhihu.com/p/35975956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in attributes[2:]:\n",
    "    info = line.split()\n",
    "    if len(info) == 0:\n",
    "        continue\n",
    "    image_id = info[0]\n",
    "    tar_img = (int(info[1:][target_idx]) + 1) / 2\n",
    "    sen_img = (int(info[1:][sen_idx]) + 1) / 2\n",
    "\n",
    "    image[image_id] = tar_img, sen_img\n",
    "    target.append(tar_img)\n",
    "    sensitive.append(sen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    " \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "images_path = Path('raw_data//img_align_celeba')\n",
    "\n",
    "images_list = list(images_path.glob('*.jpg')) # list(images_path.glob('*.png'))\n",
    "images_list_str = [ str(x) for x in images_list ]\n",
    "num = 20000\n",
    "ids = random.sample(images_list_str, 20000)\n",
    "\n",
    "sample_target = []\n",
    "sample_sensitive = []\n",
    "for path in ids:\n",
    "    sample_target.append(image[path[-10:]][0])\n",
    "    sample_sensitive.append(image[path[-10:]][1])\n",
    "\n",
    "len(sample_sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()      # 这里仅以最基本的为例\n",
    "        ])\n",
    "transform = transforms.Compose([\n",
    "            transforms.CenterCrop((178, 178)), # 从图片中间切出224*224的图片\n",
    "            transforms.Resize((128, 128)), # 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "            transforms.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]（直接除以255）\n",
    "            # transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # 标准化至[-1, 1]，规定均值和标准差\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 常用标准化\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 3, 128, 128])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.stack([transform(Image.open(image_path)) for image_path in ids[:20000]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, A = torch.tensor(sample_target).reshape(-1,1), torch.tensor(sample_sensitive).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(path, 'rb') as file:\n",
    "            data_split = json.load(file)\n",
    "        for client in data_split['users']:\n",
    "            if name == 'celeba':\n",
    "                X = split_celeba_data(data_split['user_data'][client][\"x\"]).astype(np.float32)\n",
    "            else:\n",
    "                X = np.array(data_split['user_data'][client][\"x\"]).astype(np.float32)\n",
    "\n",
    "            Y = np.array(data_split['user_data'][client][\"y\"]).astype(np.float32).reshape(-1,1)\n",
    "\n",
    "            A = np.array(data_split['user_data'][client][\"A\"]).astype(np.float32).reshape(-1,1)\n",
    "                \n",
    "            dataset = Fair_Dataset(X, Y, A)\n",
    "            data_split['user_data'][client] = dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
